{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11de302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder import Encoder\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb3264e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "num_heads = 8\n",
    "dropout = 0.1\n",
    "batch_size = 30\n",
    "max_seq_len = 200\n",
    "ffn_hidden = 2048\n",
    "num_layers = 5\n",
    "\n",
    "encoder = Encoder(d_model, ffn_hidden, num_heads, num_layers, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07918765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to encoder: torch.Size([2, 8, 512])\n",
      "Encoded input: tensor([[[-0.1969,  0.4698, -0.3321,  ..., -0.8984, -0.1075,  0.6665],\n",
      "         [ 1.6806, -1.1293,  0.5993,  ..., -0.6503,  0.4793,  1.0988],\n",
      "         [-0.8204, -0.6437,  0.2243,  ...,  1.0726,  0.2400, -0.2694],\n",
      "         ...,\n",
      "         [-0.1198, -1.3859, -1.2164,  ..., -0.6503,  0.4798,  1.0988],\n",
      "         [ 1.2989,  1.7439,  0.9382,  ...,  0.9399,  0.9789, -1.0290],\n",
      "         [ 1.1416, -0.9356,  0.6688,  ...,  2.3149, -0.4351,  2.5319]],\n",
      "\n",
      "        [[-0.1969,  0.4698, -0.3321,  ..., -0.8984, -0.1075,  0.6665],\n",
      "         [ 0.8490,  0.1816, -0.4183,  ...,  0.3876, -0.7164,  0.7251],\n",
      "         [ 1.8039,  1.0989,  0.7189,  ...,  0.4665, -0.4182, -0.2378],\n",
      "         ...,\n",
      "         [ 0.4287,  1.0654, -0.8342,  ...,  0.6827,  0.1515, -0.1442],\n",
      "         [ 1.1082,  1.7419, -0.3156,  ...,  0.6827,  0.1516, -0.1442],\n",
      "         [ 2.0446,  1.5356,  0.6120,  ...,  0.6827,  0.1517, -0.1442]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "After positional encoding: torch.Size([2, 8, 512])\n",
      "Final encoder output: torch.Size([2, 8, 512])\n",
      "Final encoder output: tensor([[[-0.1110, -0.0171, -1.5418,  ..., -1.6222, -0.2190, -0.4515],\n",
      "         [ 1.1400,  0.6129, -0.0253,  ..., -0.1838,  0.8094, -0.0410],\n",
      "         [-1.5743, -0.7689,  0.4312,  ..., -0.4273, -0.3785, -1.2920],\n",
      "         ...,\n",
      "         [ 0.3074, -1.7547, -1.1989,  ...,  0.3534, -0.9389,  0.5132],\n",
      "         [ 0.8227,  1.9666,  1.7057,  ..., -0.6358,  2.0720, -1.1721],\n",
      "         [ 1.0456, -0.1631,  0.9061,  ...,  1.6218, -1.0896,  2.0931]],\n",
      "\n",
      "        [[-0.8496, -0.5072, -0.5388,  ..., -1.6006,  0.4649,  0.6362],\n",
      "         [ 0.7701, -0.7493, -0.2858,  ..., -0.3447, -1.5100,  1.2641],\n",
      "         [ 2.0015,  1.0166,  0.3799,  ..., -0.3922, -0.2641, -0.6551],\n",
      "         ...,\n",
      "         [-0.3505,  0.9324, -1.0907,  ...,  0.0756,  1.0826, -1.0348],\n",
      "         [ 0.7475,  0.7307, -0.2730,  ..., -0.0161,  1.3121, -0.3801],\n",
      "         [-0.6637,  0.9002,  1.3806,  ..., -0.6883,  0.8317, -1.1479]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "sample = [\"The cat sat on the mat\", \"Transformers are amazing\"]\n",
    "tokens = tokenizer(sample, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "input_ids = tokens[\"input_ids\"]  # shape: (batch_size, seq_len)\n",
    "\n",
    "embedding = nn.Embedding(tokenizer.vocab_size, d_model)\n",
    "x = embedding(input_ids)  # shape: (batch_size, seq_len, d_model)\n",
    "\n",
    "output = encoder(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
